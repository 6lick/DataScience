{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Introduction to Pandas and the Titanic Data Set\n",
    "***\n",
    "\n",
    "If you haven't at least skimmed the Numpy and Pandas tutorial, **STOP** and go do that now. \n",
    "\n",
    "In this notebook you'll apply some basic Pandas tools to explore the ubiquitous **Titanic** dataset. \n",
    "\n",
    "First, as always, we'll load Numpy and Pandas using their common aliases, np and pd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a .csv file (a format that lists data separated by commas) called clean_titanic_data.csv.  We'll import the data into Pandas using the read_csv( ) function.  Depending on how you're accessing this notebook you'll use one of two options to access the data.  If you've cloned the class GitHub repository then you'll have a local copy of the data set on your machine and you can use the local file path shown below.  If you are using Azure Notebooks, or have gotten this notebook in some other way, then you will use the the web-based file path shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two different paths to the data\n",
    "# Modify the `local path` to wherever it lives on your machine\n",
    "local_path = 'clean_titanic_data.csv'\n",
    "web_path = 'https://piazza.com/class_profile/get_resource/jhaqogsdelf76h/jhv5z2opbj519u'\n",
    "\n",
    "# Select the path that works for you \n",
    "file_path = local_path \n",
    "\n",
    "# Load the data into a DataFrame \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first few rows of the DataFrame using the head( ) method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500        S  \n",
       "1      0          PC 17599  71.2833        C  \n",
       "2      0  STON/O2. 3101282   7.9250        S  \n",
       "3      0            113803  53.1000        S  \n",
       "4      0            373450   8.0500        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this you should see that each row in the DataFrame refers to a particular passenger on the Titanic.  The columns of the DataFrame give you specific information about each passenger.  The **PassengerId** is simply a unique identifier given to each passenger in the data set.  The rest of the attributes are more meaningful: \n",
    "\n",
    "- **Survived**: Indicates whether the passenger survived the sinking\n",
    "- **Pclass**: Indicates the socio-economic status of the passenger (lower number means higher class)\n",
    "- **Name**: The passenger's name \n",
    "- **Sex**: The passenger's sex \n",
    "- **Age**: The passenger's age\n",
    "- **SibSp**: The number of siblings / spouses the passenger was traveling with \n",
    "- **Parch**: The number of children / parents the passenger was traveling with \n",
    "- **Ticket**: The passenger's ticket number \n",
    "- **Fare**: How much the passenger paid for their ticket \n",
    "- **Embarked**: The passenger's port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "### Exercise 1\n",
    "***\n",
    "Determine how many people survived the disaster, and how many passengers are in the data set total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 people survived the disaster\n",
      "714\n",
      "... out of 714 people total\n"
     ]
    }
   ],
   "source": [
    "dfSurvived = df.loc[df['Survived']==1]\n",
    "people_survived = dfSurvived.PassengerId.count()\n",
    "print(\"{} people survived the disaster\".format(people_survived))\n",
    "\n",
    "people_total = df.PassengerId.count()\n",
    "print(people_total)\n",
    "print(\"... out of {} people total\".format(people_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2  \n",
    "***\n",
    "Determine how many men and how many women survived the disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 men survived the disaster\n",
      "197 women survived the disaster\n"
     ]
    }
   ],
   "source": [
    "\n",
    "male_survived = len(dfSurvived.loc[dfSurvived['Sex']=='male'] )\n",
    "female_survived = len(dfSurvived.loc[dfSurvived['Sex']=='female']) \n",
    "print(\"{} men survived the disaster\".format(male_survived))\n",
    "print(\"{} women survived the disaster\".format(female_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "***\n",
    "Determine how many children at or under the age of 12 survived the disaster, and how many children were present total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 children survived the disaster\n",
      "... out of 68 children total\n"
     ]
    }
   ],
   "source": [
    "children_survived = len(dfSurvived.loc[dfSurvived['Age']<12]) \n",
    "print(\"{} children survived the disaster\".format(children_survived))\n",
    "\n",
    "children_total = len(df.loc[df['Age']<12])\n",
    "\n",
    "print(\"... out of {} children total\".format(children_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to ponder:**  Reflect on your answers to Exercises 1 and 3.  Do you think being a child makes you more or less likely to survive the sinking of the Titanic?\n",
    "\n",
    "Later in this course, we will learn how to formally test your hypothesis.  You can start to get excited... *now!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 \n",
    "***\n",
    "The **SibSp** and **Parch** attributes tell us the number of siblings/spouses and parents/children each passenger had on board.  Create a new column in the DataFrame called **Family** that indicates how many siblings/spouses/parents/children a passenger was traveling with. Then report how many people survived that were traveling with 3 or more family members. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 people traveling with 3 or more family members survived the disaster\n"
     ]
    }
   ],
   "source": [
    "df[\"Family\"] = df['SibSp'] + df['Parch']\n",
    "dfS = df.loc[df['Survived'] == 1 ] \n",
    "family_survived = len(dfS.loc[dfS['Family']>3])\n",
    "print(\"{} people traveling with 3 or more family members survived the disaster\".format(family_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 \n",
    "***\n",
    "In this exercise you will write some code to predict whether a person survived the disaster based on their information.  Obviously, you'll want to ignore the **Survived** attribute for this to avoid cheating. You'll store your predictions ($1$ if you predict survived, $0$ if you predict died) in a column of the DataFrame called **Prediction**.  You can then use the following function to see how accurate your prediction was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 72 points : 20, performance 72.22%\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "88           114         0       3   \n",
      "108          137         1       1   \n",
      "277          345         0       2   \n",
      "189          235         0       2   \n",
      "14            16         1       2   \n",
      "83           107         1       3   \n",
      "308          386         0       2   \n",
      "576          725         1       1   \n",
      "270          338         1       1   \n",
      "272          340         0       1   \n",
      "618          776         0       3   \n",
      "115          145         0       2   \n",
      "574          723         0       2   \n",
      "463          586         1       1   \n",
      "369          462         0       3   \n",
      "140          175         0       1   \n",
      "130          163         0       3   \n",
      "372          466         0       3   \n",
      "283          353         0       3   \n",
      "98           125         0       1   \n",
      "137          172         0       3   \n",
      "468          592         1       1   \n",
      "686          859         1       3   \n",
      "236          293         0       2   \n",
      "175          219         1       1   \n",
      "492          624         0       3   \n",
      "476          605         1       1   \n",
      "7              9         1       3   \n",
      "25            34         0       2   \n",
      "215          268         1       3   \n",
      "..           ...       ...     ...   \n",
      "599          753         0       3   \n",
      "135          170         0       3   \n",
      "228          284         1       3   \n",
      "542          686         0       2   \n",
      "592          746         0       1   \n",
      "691          866         1       2   \n",
      "683          856         1       3   \n",
      "352          440         0       2   \n",
      "377          474         1       2   \n",
      "230          287         1       3   \n",
      "621          781         1       3   \n",
      "12            14         0       3   \n",
      "20            24         1       1   \n",
      "310          388         1       2   \n",
      "573          722         0       3   \n",
      "41            57         1       2   \n",
      "679          852         0       3   \n",
      "697          873         0       1   \n",
      "514          652         1       2   \n",
      "360          449         1       3   \n",
      "79           103         0       1   \n",
      "219          273         1       2   \n",
      "128          161         0       3   \n",
      "258          322         0       3   \n",
      "386          485         1       1   \n",
      "303          380         0       3   \n",
      "627          788         0       3   \n",
      "423          535         0       3   \n",
      "417          526         0       3   \n",
      "204          254         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "88                             Jussila, Miss. Katriina  female  20.0      1   \n",
      "108                       Newsom, Miss. Helen Monypeny  female  19.0      0   \n",
      "277                            Fox, Mr. Stanley Hubert    male  36.0      0   \n",
      "189                  Leyson, Mr. Robert William Norman    male  24.0      0   \n",
      "14                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
      "83                    Salkjelsvik, Miss. Anna Kristine  female  21.0      0   \n",
      "308                          Davies, Mr. Charles Henry    male  18.0      0   \n",
      "576                      Chambers, Mr. Norman Campbell    male  27.0      1   \n",
      "270                    Burns, Miss. Elizabeth Margaret  female  41.0      0   \n",
      "272                       Blackwell, Mr. Stephen Weart    male  45.0      0   \n",
      "618            Myhrman, Mr. Pehr Fabian Oliver Malkolm    male  18.0      0   \n",
      "115                         Andrew, Mr. Edgardo Samuel    male  18.0      0   \n",
      "574                       Gillespie, Mr. William Henry    male  34.0      0   \n",
      "463                                Taussig, Miss. Ruth  female  18.0      0   \n",
      "369                                Morley, Mr. William    male  34.0      0   \n",
      "140                            Smith, Mr. James Clinch    male  56.0      0   \n",
      "130                         Bengtsson, Mr. John Viktor    male  26.0      0   \n",
      "372                    Goncalves, Mr. Manuel Estanslas    male  38.0      0   \n",
      "283                                 Elias, Mr. Tannous    male  15.0      1   \n",
      "98                         White, Mr. Percival Wayland    male  54.0      0   \n",
      "137                               Rice, Master. Arthur    male   4.0      4   \n",
      "468    Stephenson, Mrs. Walter Bertram (Martha Eustis)  female  52.0      1   \n",
      "686              Baclini, Mrs. Solomon (Latifa Qurban)  female  24.0      0   \n",
      "236                             Levy, Mr. Rene Jacques    male  36.0      0   \n",
      "175                              Bazzani, Miss. Albina  female  32.0      0   \n",
      "492                        Hansen, Mr. Henry Damsgaard    male  21.0      0   \n",
      "476                    Homer, Mr. Harry (\"Mr E Haven\")    male  35.0      0   \n",
      "7    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "25                               Wheadon, Mr. Edward H    male  66.0      0   \n",
      "215                           Persson, Mr. Ernst Ulrik    male  25.0      1   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "599                   Vande Velde, Mr. Johannes Joseph    male  33.0      0   \n",
      "135                                      Ling, Mr. Lee    male  28.0      0   \n",
      "228                         Dorking, Mr. Edward Arthur    male  19.0      0   \n",
      "542             Laroche, Mr. Joseph Philippe Lemercier    male  25.0      1   \n",
      "592                       Crosby, Capt. Edward Gifford    male  70.0      1   \n",
      "691                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
      "683                         Aks, Mrs. Sam (Leah Rosen)  female  18.0      0   \n",
      "352             Kvillner, Mr. Johan Henrik Johannesson    male  31.0      0   \n",
      "377       Jerwan, Mrs. Amin S (Marie Marthe Thuillard)  female  23.0      0   \n",
      "230                            de Mulder, Mr. Theodore    male  30.0      0   \n",
      "621                               Ayoub, Miss. Banoura  female  13.0      0   \n",
      "12                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
      "20                        Sloper, Mr. William Thompson    male  28.0      0   \n",
      "310                                   Buss, Miss. Kate  female  36.0      0   \n",
      "573                          Jensen, Mr. Svend Lauritz    male  17.0      1   \n",
      "41                                   Rugg, Miss. Emily  female  21.0      0   \n",
      "679                                Svensson, Mr. Johan    male  74.0      0   \n",
      "697                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
      "514                                Doling, Miss. Elsie  female  18.0      0   \n",
      "360                     Baclini, Miss. Marie Catherine  female   5.0      2   \n",
      "79                           White, Mr. Richard Frasar    male  21.0      0   \n",
      "219          Mellinger, Mrs. (Elizabeth Anne Maidment)  female  41.0      0   \n",
      "128                           Cribb, Mr. John Hatfield    male  44.0      0   \n",
      "258                                   Danoff, Mr. Yoto    male  27.0      0   \n",
      "386                            Bishop, Mr. Dickinson H    male  25.0      1   \n",
      "303                        Gustafsson, Mr. Karl Gideon    male  19.0      0   \n",
      "627                          Rice, Master. George Hugh    male   8.0      4   \n",
      "423                                Cacic, Miss. Marija  female  30.0      0   \n",
      "417                                 Farrell, Mr. James    male  40.5      0   \n",
      "204                           Lobb, Mr. William Arthur    male  30.0      1   \n",
      "\n",
      "     Parch              Ticket      Fare Embarked  Family  cleaned  \n",
      "88       0                4136    9.8250        S       1        1  \n",
      "108      2               11752   26.2833        S       2        1  \n",
      "277      0              229236   13.0000        S       0        0  \n",
      "189      0          C.A. 29566   10.5000        S       0        0  \n",
      "14       0              248706   16.0000        S       0        1  \n",
      "83       0              343120    7.6500        S       0        1  \n",
      "308      0        S.O.C. 14879   73.5000        S       0        0  \n",
      "576      0              113806   53.1000        S       1        0  \n",
      "270      0               16966  134.5000        C       0        1  \n",
      "272      0              113784   35.5000        S       0        0  \n",
      "618      0              347078    7.7500        S       0        0  \n",
      "115      0              231945   11.5000        S       0        0  \n",
      "574      0               12233   13.0000        S       0        0  \n",
      "463      2              110413   79.6500        S       2        1  \n",
      "369      0              364506    8.0500        S       0        0  \n",
      "140      0               17764   30.6958        C       0        0  \n",
      "130      0              347068    7.7750        S       0        0  \n",
      "372      0  SOTON/O.Q. 3101306    7.0500        S       0        0  \n",
      "283      1                2695    7.2292        C       2        0  \n",
      "98       1               35281   77.2875        S       1        0  \n",
      "137      1              382652   29.1250        Q       5        0  \n",
      "468      0               36947   78.2667        C       1        1  \n",
      "686      3                2666   19.2583        C       3        1  \n",
      "236      0       SC/Paris 2163   12.8750        C       0        0  \n",
      "175      0               11813   76.2917        C       0        1  \n",
      "492      0              350029    7.8542        S       0        0  \n",
      "476      0              111426   26.5500        C       0        0  \n",
      "7        2              347742   11.1333        S       2        1  \n",
      "25       0          C.A. 24579   10.5000        S       0        0  \n",
      "215      0              347083    7.7750        S       1        0  \n",
      "..     ...                 ...       ...      ...     ...      ...  \n",
      "599      0              345780    9.5000        S       0        0  \n",
      "135      0                1601   56.4958        S       0        0  \n",
      "228      0          A/5. 10482    8.0500        S       0        0  \n",
      "542      2       SC/Paris 2123   41.5792        C       3        0  \n",
      "592      1           WE/P 5735   71.0000        S       2        0  \n",
      "691      0              236852   13.0000        S       0        1  \n",
      "683      1              392091    9.3500        S       1        1  \n",
      "352      0          C.A. 18723   10.5000        S       0        0  \n",
      "377      0     SC/AH Basle 541   13.7917        C       0        1  \n",
      "230      0              345774    9.5000        S       0        0  \n",
      "621      0                2687    7.2292        C       0        1  \n",
      "12       5              347082   31.2750        S       6        0  \n",
      "20       0              113788   35.5000        S       0        0  \n",
      "310      0               27849   13.0000        S       0        1  \n",
      "573      0              350048    7.0542        S       1        0  \n",
      "41       0          C.A. 31026   10.5000        S       0        1  \n",
      "679      0              347060    7.7750        S       0        0  \n",
      "697      0                 695    5.0000        S       0        0  \n",
      "514      1              231919   23.0000        S       1        1  \n",
      "360      1                2666   19.2583        C       3        1  \n",
      "79       1               35281   77.2875        S       1        0  \n",
      "219      1              250644   19.5000        S       1        1  \n",
      "128      1              371362   16.1000        S       1        0  \n",
      "258      0              349219    7.8958        S       0        0  \n",
      "386      0               11967   91.0792        C       1        0  \n",
      "303      0              347069    7.7750        S       0        0  \n",
      "627      1              382652   29.1250        Q       5        0  \n",
      "423      0              315084    8.6625        S       0        1  \n",
      "417      0              367232    7.7500        Q       0        0  \n",
      "204      0           A/5. 3336   16.1000        S       1        0  \n",
      "\n",
      "[642 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time \n",
    "#convert to numeric data\n",
    "df['cleaned']= np.where(df['Sex']=='male',0,1)\n",
    "#relevant attributes\n",
    "features = ['Pclass','cleaned', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "#prediction model \n",
    "model = GaussianNB()\n",
    "#splitting data into test and train \n",
    "X_train, X_test = train_test_split(df, test_size=.1, random_state=int(time.time()))\n",
    "model.fit(\n",
    "    X_train[features].values,\n",
    "    X_train[\"Survived\"])\n",
    "predict = model.predict(X_test[features])\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Survived\"] != predict).sum(),\n",
    "          100*(1-(X_test[\"Survived\"] != predict).sum()/X_test.shape[0])\n",
    "))\n",
    "# classifierModel = GaussianNB()\n",
    "def score_prediction(df):\n",
    "    '''\n",
    "    Function to score predictions.  \n",
    "    Takes entire DataFrame as sole argument. \n",
    "    '''\n",
    "    df['cleaned']= np.where(df['Sex']=='male',0,1)\n",
    "    #relevant attributes\n",
    "    features = ['Pclass','cleaned', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "    #prediction model \n",
    "    model = GaussianNB()\n",
    "    #splitting data into test and train \n",
    "    X_train, X_test = train_test_split(df, test_size=.1, random_state=int(time.time()))\n",
    "    model.fit(\n",
    "        X_train[features].values,\n",
    "        X_train[\"Survived\"])\n",
    "    predict = model.predict(X_test[features])\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "          .format(\n",
    "              X_test.shape[0],\n",
    "              (X_test[\"Survived\"] != predict).sum(),\n",
    "              100*(1-(X_test[\"Survived\"] != predict).sum()/X_test.shape[0])\n",
    "    ))\n",
    "\n",
    "\n",
    "#     acc = (df[\"Survived\"]==df[\"Prediction\"]).sum() / len(df)\n",
    "#     print(\"Your accuracy is {0:.1f}%\".format(100*acc))\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways that we can accomplish this.  The first method we'll highlight is one that loops over every row in the DataFrame, makes a decision based on that row's attributes, and then sets the relevant prediction in the **Prediction** column.  As an example, we'll use a very naive heuristic that predicts that all males survive and all females die. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for passenger_index, passenger in df.iterrows():\n",
    "    df.loc[passenger_index, \"Prediction\"] = 1 if df.loc[passenger_index, \"Sex\"] == 'male' else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that our code actually did something using the head( ) function and observing that we do in fact have a column called **Prediction** populated with $1$'s and $0$'s. You can see that the $1$'s in the **Prediction** column do in-fact line up with \"male\" in the **Sex** column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we did by passing our DataFrame into the score_prediction( ) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 72 points : 13, performance 81.94%\n"
     ]
    }
   ],
   "source": [
    "score_prediction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we see that our naive prediction netted us a 22% prediction accuracy (which isn't very good, but you're going to make it better). \n",
    "\n",
    "OK, so looping over the data is one option, but in Python, unfortunately, it's not a very good option.  Python is an interpreted language, which means that loops are slow.  We didn't really notice it here, because our DataFrame only has around 700 rows in it, but on data sets with hundreds of thousands or millions of entries, loops can grind your day to a complete halt.  \n",
    "\n",
    "It's better to use vectorized methods like Pandas apply( ) function combined with Python lambda functions.  One way to accomplish the same results as above is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prediction\"] = df[\"Sex\"].apply(lambda s: 1 if s==\"male\" else 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that this produces the same result as the loop-based method. We can compare the speeds of the apply( ) method and the loop-based method using the Jupyter magic %timeit command.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop-based method \n",
    "print(\"Timing loop-based method: \")\n",
    "%timeit for passenger_index, passenger in df.iterrows(): df.loc[passenger_index, \"Prediction\"] = 1 if df.loc[passenger_index, \"Sex\"] == 'male' else 0\n",
    "    \n",
    "# Apply-based method \n",
    "print(\"Timing apply-based method: \")\n",
    "%timeit df[\"Prediction\"] = df[\"Sex\"].apply(lambda s: 1 if s==\"male\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here ms is milliseconds and $\\mu\\textrm{s}$ is **micro**seconds.  You can hopefully see that the apply method is **tremendously** faster than the loop-based method. \n",
    "\n",
    "OK, let's do one more slightly more complicated example so that we can see how to use the apply( ) function with multiple inputs.  Suppose say that you want to predict that a person survived if they are male **AND** they were traveling alone (probably not a good heuristic but just go with it).  To do this we need values from both the **Sex** column and the **Family** column.  Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prediction\"] = df.apply(lambda row: 1 if row[\"Sex\"]==\"male\" and row[\"Family\"]==0 else 0, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the apply( ) function is applied to the entire DataFrame and the object passed to the lambda function is an entire row of the DataFrame.  We can then carve off the elements from the columns we're interested in and do our thing.  Let's see how we did! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_prediction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**W00T!** Minor improvement! OK, so you're job is to explore the data and see if you can cook up a custom prediction heuristic that does better than 31.1%!  I've created a Titanic Leaderboard post on Piazza.  If you get an accuracy you're proud of, post it there along with a description of what you did! \n",
    "\n",
    "**Question to ponder:**  Compare the prediction accuracies that we have found using **Sex** as the only feature in our model, and using both **Sex** and **Family**.  What do you think is the effect of traveling with family on a man's odds of surviving the incident?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
